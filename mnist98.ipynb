{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist98.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radstrawhat/Awesome-pytorch-list/blob/master/mnist98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTbb3ms_CMmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlZb-p6gCnzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=90\n",
        "train = dsets.MNIST(root = './data', train = True,\n",
        "                        transform = transforms.ToTensor(), download = True)\n",
        "\n",
        "test = dsets.MNIST(root = './data', train = False,\n",
        "                       transform = transforms.ToTensor())\n",
        "train_batch = torch.utils.data.DataLoader(dataset = train,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "\n",
        "test_batch = torch.utils.data.DataLoader(dataset = test,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-n0LZEUCxf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQhK9XBZC7GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net(784, 500, 10)\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam( net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCuTT5eDSCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1580
        },
        "outputId": "c04694b8-cd1d-422e-d86e-3f199656d038"
      },
      "source": [
        "for epoch in range(15):\n",
        "  for i ,(images,labels) in enumerate(train_batch):\n",
        "    images = Variable(images.view(-1,28*28)).cuda()\n",
        "    labels = Variable(labels).cuda()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Epoch [%d/%d],  Loss: %.4f'\n",
        "                 %(epoch+1, 15,  loss.data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/15],  Loss: 0.2971\n",
            "Epoch [1/15],  Loss: 0.2062\n",
            "Epoch [1/15],  Loss: 0.3351\n",
            "Epoch [1/15],  Loss: 0.2233\n",
            "Epoch [1/15],  Loss: 0.1490\n",
            "Epoch [1/15],  Loss: 0.1488\n",
            "Epoch [2/15],  Loss: 0.1793\n",
            "Epoch [2/15],  Loss: 0.1080\n",
            "Epoch [2/15],  Loss: 0.0740\n",
            "Epoch [2/15],  Loss: 0.0323\n",
            "Epoch [2/15],  Loss: 0.0808\n",
            "Epoch [2/15],  Loss: 0.2121\n",
            "Epoch [3/15],  Loss: 0.0888\n",
            "Epoch [3/15],  Loss: 0.1471\n",
            "Epoch [3/15],  Loss: 0.1488\n",
            "Epoch [3/15],  Loss: 0.1008\n",
            "Epoch [3/15],  Loss: 0.0903\n",
            "Epoch [3/15],  Loss: 0.1768\n",
            "Epoch [4/15],  Loss: 0.1029\n",
            "Epoch [4/15],  Loss: 0.0641\n",
            "Epoch [4/15],  Loss: 0.0298\n",
            "Epoch [4/15],  Loss: 0.0537\n",
            "Epoch [4/15],  Loss: 0.0868\n",
            "Epoch [4/15],  Loss: 0.0103\n",
            "Epoch [5/15],  Loss: 0.0353\n",
            "Epoch [5/15],  Loss: 0.0118\n",
            "Epoch [5/15],  Loss: 0.0389\n",
            "Epoch [5/15],  Loss: 0.0409\n",
            "Epoch [5/15],  Loss: 0.0155\n",
            "Epoch [5/15],  Loss: 0.0752\n",
            "Epoch [6/15],  Loss: 0.0225\n",
            "Epoch [6/15],  Loss: 0.0443\n",
            "Epoch [6/15],  Loss: 0.0132\n",
            "Epoch [6/15],  Loss: 0.0805\n",
            "Epoch [6/15],  Loss: 0.0118\n",
            "Epoch [6/15],  Loss: 0.0117\n",
            "Epoch [7/15],  Loss: 0.0252\n",
            "Epoch [7/15],  Loss: 0.0268\n",
            "Epoch [7/15],  Loss: 0.0083\n",
            "Epoch [7/15],  Loss: 0.0504\n",
            "Epoch [7/15],  Loss: 0.0261\n",
            "Epoch [7/15],  Loss: 0.0235\n",
            "Epoch [8/15],  Loss: 0.0059\n",
            "Epoch [8/15],  Loss: 0.0437\n",
            "Epoch [8/15],  Loss: 0.0079\n",
            "Epoch [8/15],  Loss: 0.0110\n",
            "Epoch [8/15],  Loss: 0.0082\n",
            "Epoch [8/15],  Loss: 0.0173\n",
            "Epoch [9/15],  Loss: 0.0065\n",
            "Epoch [9/15],  Loss: 0.0290\n",
            "Epoch [9/15],  Loss: 0.0099\n",
            "Epoch [9/15],  Loss: 0.0053\n",
            "Epoch [9/15],  Loss: 0.0095\n",
            "Epoch [9/15],  Loss: 0.0010\n",
            "Epoch [10/15],  Loss: 0.0018\n",
            "Epoch [10/15],  Loss: 0.0211\n",
            "Epoch [10/15],  Loss: 0.0008\n",
            "Epoch [10/15],  Loss: 0.0028\n",
            "Epoch [10/15],  Loss: 0.0128\n",
            "Epoch [10/15],  Loss: 0.0099\n",
            "Epoch [11/15],  Loss: 0.0031\n",
            "Epoch [11/15],  Loss: 0.0018\n",
            "Epoch [11/15],  Loss: 0.0048\n",
            "Epoch [11/15],  Loss: 0.0030\n",
            "Epoch [11/15],  Loss: 0.0082\n",
            "Epoch [11/15],  Loss: 0.0042\n",
            "Epoch [12/15],  Loss: 0.0060\n",
            "Epoch [12/15],  Loss: 0.0050\n",
            "Epoch [12/15],  Loss: 0.0012\n",
            "Epoch [12/15],  Loss: 0.0087\n",
            "Epoch [12/15],  Loss: 0.0007\n",
            "Epoch [12/15],  Loss: 0.0005\n",
            "Epoch [13/15],  Loss: 0.0032\n",
            "Epoch [13/15],  Loss: 0.0058\n",
            "Epoch [13/15],  Loss: 0.0024\n",
            "Epoch [13/15],  Loss: 0.0022\n",
            "Epoch [13/15],  Loss: 0.0142\n",
            "Epoch [13/15],  Loss: 0.0229\n",
            "Epoch [14/15],  Loss: 0.0029\n",
            "Epoch [14/15],  Loss: 0.0077\n",
            "Epoch [14/15],  Loss: 0.0157\n",
            "Epoch [14/15],  Loss: 0.0098\n",
            "Epoch [14/15],  Loss: 0.0002\n",
            "Epoch [14/15],  Loss: 0.0018\n",
            "Epoch [15/15],  Loss: 0.0004\n",
            "Epoch [15/15],  Loss: 0.0005\n",
            "Epoch [15/15],  Loss: 0.0028\n",
            "Epoch [15/15],  Loss: 0.0078\n",
            "Epoch [15/15],  Loss: 0.0037\n",
            "Epoch [15/15],  Loss: 0.0002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWu6pklD_XS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "150036b5-8cb4-49c8-f74e-6ddd0fd508ba"
      },
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "for images,labels in test_batch:\n",
        "  images = Variable(images.view(-1,28*28)).cuda()\n",
        "  labels = labels.cuda()\n",
        "  \n",
        "  output = net(images)\n",
        "  _, predicted = torch.max(output,1)\n",
        "  correct += (predicted == labels).sum()\n",
        "  total += labels.size(0)\n",
        "\n",
        "print('Acc: %.4f %%' %((100*correct)/(total+1)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 98.0000 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}